{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hritikahere/Next-Word-Prediction-using-LSTM/blob/main/Next_word_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsC0KbjeOMvR"
      },
      "source": [
        "Importing required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ALpt_XNyKXrK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle \n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvFnlxBOcLl"
      },
      "source": [
        "Load and Pre-Process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "fgOe6BYJOgyT",
        "outputId": "249089d4-e910-4481-e278-809821a74910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of The Blue Castle, by Lucy Maud Montgomery This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before usi'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = open(\"blue_castle.txt\", \"r\", encoding = \"utf8\" )\n",
        "\n",
        "#store file in list \n",
        "lines = []\n",
        "for i in file:\n",
        "     lines.append(i)\n",
        "\n",
        "#Convert list to string \n",
        "data = \"\"\n",
        "for i in lines:\n",
        "    data = '  '. join(lines)\n",
        "\n",
        "#replace unnecessary stuff with space\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
        "\n",
        "#remove unnecessary spaces\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8jwCmplSFTk",
        "outputId": "01a105d6-67be-47ca-efb2-a0591776ca8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "402906"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu8CN4SISaq0"
      },
      "source": [
        "Apply tokenization and some other changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y03WRnhgPF7X",
        "outputId": "d0e5c748-dcaa-46bf-c651-49b70526ccce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 112, 97, 587, 4, 1, 94, 147, 58, 2383, 2384, 1818, 51, 587, 42]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "#saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl','wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO0bo0KBTrZn",
        "outputId": "0c2bec4b-7e71-4453-8747-853d6c902e5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "72052"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sequence_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dG3LURqTxhK",
        "outputId": "9d9152dd-19d3-4db9-9ff8-dd91f0b0265a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8413\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6CdiNNyT72r",
        "outputId": "df490cc2-a25e-4722-eb82-03d714bc19e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Length if sequences are: 72049\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[   1,  112,   97,  587],\n",
              "       [ 112,   97,  587,    4],\n",
              "       [  97,  587,    4,    1],\n",
              "       [ 587,    4,    1,   94],\n",
              "       [   4,    1,   94,  147],\n",
              "       [   1,   94,  147,   58],\n",
              "       [  94,  147,   58, 2383],\n",
              "       [ 147,   58, 2383, 2384],\n",
              "       [  58, 2383, 2384, 1818],\n",
              "       [2383, 2384, 1818,   51]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range (3, len(sequence_data)):\n",
        "  words = sequence_data[i-3:i+1]\n",
        "  sequences.append(words)\n",
        "\n",
        "print(\"The Length if sequences are:\" , len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l32bESJcalIL"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "  X.append(i[0:3])\n",
        "  y.append(i[3])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkefHZhXbIgp",
        "outputId": "0d68bbc6-5575-4c0e-a8e7-b4d9809f5843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: [[   1  112   97]\n",
            " [ 112   97  587]\n",
            " [  97  587    4]\n",
            " [ 587    4    1]\n",
            " [   4    1   94]\n",
            " [   1   94  147]\n",
            " [  94  147   58]\n",
            " [ 147   58 2383]\n",
            " [  58 2383 2384]\n",
            " [2383 2384 1818]]\n",
            "Response: [ 587    4    1   94  147   58 2383 2384 1818   51]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data:\", X[:10])\n",
        "print(\"Response:\", y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2SQNlaebUhi",
        "outputId": "c0dc3f53-9906-49ff-d0bf-1679294a28c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrtFfmMZbmGD"
      },
      "source": [
        "Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HudAYj4RboUh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-12 12:31:46.270069: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-03-12 12:31:46.309631: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation= \"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPRinwv2cdqh",
        "outputId": "c3b70517-b827-4fae-924a-1cb1e67e4de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             84130     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8413)              8421413   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21554543 (82.22 MB)\n",
            "Trainable params: 21554543 (82.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1f-zb9FchNl"
      },
      "source": [
        "Plot the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "C6LiognZckNb",
        "outputId": "a5521ed4-6966-4720-ceb8-936fe5a41bb3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.utils.vis_utils'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m      4\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2WJLEkBeCGQ"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayoSNdE1eETe",
        "outputId": "3ef20856-644e-4b9a-9f16-3f7c383c0ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1126/1126 [==============================] - 33s 21ms/step - loss: 6.7736\n",
            "Epoch 2/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 6.2607\n",
            "Epoch 3/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 5.8552\n",
            "Epoch 4/20\n",
            "1126/1126 [==============================] - 19s 17ms/step - loss: 5.5418\n",
            "Epoch 5/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 5.2844\n",
            "Epoch 6/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 5.0524\n",
            "Epoch 7/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 4.8328\n",
            "Epoch 8/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 4.6022\n",
            "Epoch 9/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 4.3600\n",
            "Epoch 10/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 4.1134\n",
            "Epoch 11/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 3.8681\n",
            "Epoch 12/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 3.6255\n",
            "Epoch 13/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 3.3982\n",
            "Epoch 14/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 3.1878\n",
            "Epoch 15/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 2.9903\n",
            "Epoch 16/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 2.8062\n",
            "Epoch 17/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 2.6274\n",
            "Epoch 18/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 2.4612\n",
            "Epoch 19/20\n",
            "1126/1126 [==============================] - 19s 17ms/step - loss: 2.2942\n",
            "Epoch 20/20\n",
            "1126/1126 [==============================] - 18s 16ms/step - loss: 2.1342\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c5b08ab80>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_word.h5\", monitor='loss', verbise=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=20, batch_size=64, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg5fPgdUe1_n"
      },
      "source": [
        "Lets Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feah3fIge4tG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "#Load the model and tokenizer\n",
        "model = load_model('next_word.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predict_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value == preds:\n",
        "      predicted_word = key\n",
        "      break\n",
        "\n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULHNEn1XeAmq",
        "outputId": "a5dcc3ff-0273-43cc-b914-1760f0f108bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your line:The Project Gutenberg\n",
            "['The', 'Project', 'Gutenberg']\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "tm\n",
            "Enter your line:The Project Gutenberg\n",
            "['The', 'Project', 'Gutenberg']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "tm\n",
            "Enter your line:The Project Gutenberg\n",
            "['The', 'Project', 'Gutenberg']\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "tm\n",
            "Enter your line:The Project Gutenberg eBook of\n",
            "['Gutenberg', 'eBook', 'of']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "the\n",
            "Enter your line:He was quite\n",
            "['He', 'was', 'quite']\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "a\n",
            "Enter your line:however, it may all come to\n",
            "['all', 'come', 'to']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "the\n"
          ]
        }
      ],
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line:\")\n",
        "\n",
        "  if text == \"0\":\n",
        "    print(\"Execution completed....\")\n",
        "    break\n",
        "  \n",
        "  else:\n",
        "    try:\n",
        "      text: list[str] = text.split(\" \")\n",
        "      text = text[-3:]\n",
        "      print(text)\n",
        "\n",
        "      Predict_Next_Words(model, tokenizer, text)\n",
        "\n",
        "    \n",
        "    except Exception as e:\n",
        "       print(\"Error occured: \",e)\n",
        "       continue"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMv4kKxl5FKjFqC/jnzgmSB",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
